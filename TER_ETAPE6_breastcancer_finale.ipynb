{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                    APRENTISSAGE SEMI-SUPERVISE \n",
    "###                                               (DATASET DE CLASSIFICATION : BREAST_CANCER DE SK-LEARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (10%), non-LAB (80%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (10%), non-LAB (80%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (102, 30)\n",
      "-non_LAB: (410, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.9898245614035088\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB \n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.80, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (10% LAB/ 80% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (10%), non-LAB (80%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique \n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (20%), non-LAB (70%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (20%), non-LAB (70%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (153, 30)\n",
      "-non_LAB: (359, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB \n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.7, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (20% LAB/ 70% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (20%), non-LAB (70%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique \n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (30%), non-LAB (60%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (30%), non-LAB (60%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (204, 30)\n",
      "-non_LAB: (308, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.9711256718063035\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB \n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.60, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (30% LAB/ 60% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (30%), non-LAB (60%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique \n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (40%), non-LAB (50%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (40%), non-LAB (50%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (256, 30)\n",
      "-non_LAB: (256, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.96\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB \n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.50, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (40% LAB/ 50% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (40%), non-LAB (50%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique\n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (50%), non-LAB (40%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (50%), non-LAB (40%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (307, 30)\n",
      "-non_LAB: (205, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB \n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.40, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (50% LAB/ 40% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (50%), non-LAB (40%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique\n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (60%), non-LAB (30%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (60%), non-LAB (30%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (358, 30)\n",
      "-non_LAB: (154, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.95\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB \n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.30, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (60% LAB/ 30% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (60%), non-LAB (30%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique\n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (70%), non-LAB (20%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (70%), non-LAB (20%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (409, 30)\n",
      "-non_LAB: (103, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.9488367943075423\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB \n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.20, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (70% LAB/ 20% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (70%), non-LAB (20%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique\n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB (80%), non-LAB (10%), TEST (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "LAB (80%), non-LAB (10%), TEST (10%)  : \n",
      "                                                 \n",
      "-LAB : (460, 30)\n",
      "-non_LAB: (52, 30)\n",
      "-TEST : (57, 30)\n",
      "_________________________________________________\n",
      "Score de prédiction :  0.95\n"
     ]
    }
   ],
   "source": [
    "#Bibliothèques\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import zero_one_loss, accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# 1 - Téléchargement et traitement du dataset breast_cancer \n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2 - Préparation du dataset semi-supervisé\n",
    "# Découpage Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y)\n",
    "# Découpage LAB/non-LAB\n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.10, random_state=1, stratify=y_train)\n",
    "#Ensemble de trainig 90% (80% LAB/ 10% non-LAB)\n",
    "print(\"_________________________________________________\")\n",
    "print(\"LAB (80%), non-LAB (10%), TEST (10%)  : \")\n",
    "print(\"                                                 \")\n",
    "print('-LAB :', X_train_lab.shape)\n",
    "print('-non_LAB:', X_train_unlab.shape)\n",
    "#Ensemble de test 10%\n",
    "print('-TEST :', X_test.shape)\n",
    "\n",
    "\n",
    "# 3 - Normalisation\n",
    "#scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "#X_train=scaler.transform(X_train)\n",
    "#X_test=scaler.transform(X_test)\n",
    "\n",
    "# Définition d'un modele MLP (avec paramètres par défaut car il a donné déja de bons résultats)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "\n",
    "# Entrainement du modele sur le dataset labelisé\n",
    "mlp.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "\n",
    "#Self Trainig\n",
    "mlp.predict_proba(X_test[:])\n",
    "mlp.predict(X_test[:, :])\n",
    "\n",
    "#Métrique\n",
    "print(\"_________________________________________________\")\n",
    "print(\"Score de prédiction : \",mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variation de la métrique (score de prédiction) en fonction des proportions LAB/non-LAB \n",
    "#### PS : résultats copiés de l'Excel\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tLAB (10%) / non-LAB (80%)\tLAB (20%) / non-LAB (70%)\tLAB (30%) / non-LAB (60%)\tLAB (40%) / non-LAB (50%)\tLAB (50%) / non-LAB (40%)\tLAB (60%) / non-LAB (30%)\tLAB (70%) / non-LAB (20%)\tLAB (80%) / non-LAB (10%)\n",
    "Score de prédiction\t0,989824561\t0,98\t0,971125672\t0,96\t0,96\t0,95\t0,948836794\t0,95\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB (90%), non-LAB (0%), TEST (10%)\n",
    "##### Il s'agit de l'apprentissage supervisé (étape 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB (0%), non-LAB (90%), TEST (10%)\n",
    "##### Il s'agit de l'apprentissage non-supervisé (Machines Boltzmann restreintes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
