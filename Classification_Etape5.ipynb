{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Bibliothèques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import zero_one_loss, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Chargement de données depuis le fichier 'fetal_health.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 22)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fetal_health.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.  Correction de données manquantes : exemple de complétion de ces valeurs par la moyenne de la colonne\n",
    "PS : Nous n'avons pas de valeurs manquantes donc ce bout de code ne va pas influencer notre code ou données  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(data)\n",
    "data=imp.transform(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Séprataion des attributs (Inputs) et de l'attribut objectif (Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_FEATURES=21\n",
    "X=data[:,0:NB_FEATURES]         # Features: inputs (21 premières colonnes)\n",
    "y=data[:,NB_FEATURES:].ravel()  # Target : output/ (Dernière colonne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Découpage de l'ensemble de données : 80% TRAINING, 20% TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Affihage des quelques informations concernant notre dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> Taille du dataset / nombre d'instances :\t 2126 \n",
      " >>> Nombre d'attributs / Inputs : \t\t 21 \n",
      " >>> Taille du dataset d'entrainement : \t 1700\n",
      " >>> Taille du dataset de test : \t\t 426\n"
     ]
    }
   ],
   "source": [
    "print(f\" >>> Taille du dataset / nombre d'instances :\\t {data.shape[0]} \")\n",
    "print(f\" >>> Nombre d'attributs / Inputs : \\t\\t {NB_FEATURES} \")\n",
    "print(f\" >>> Taille du dataset d'entrainement : \\t {X_train.shape[0]}\")\n",
    "print(f\" >>> Taille du dataset de test : \\t\\t {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation\n",
    "scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2 : Paramètres par défaut\n",
    "#### 8. Création d'un modèle de classification avec les paramètres par défaut de ScikitLearn + apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp =MLPClassifier(hidden_layer_sizes=(100,), activation='relu',  solver='adam',\n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001,\n",
    "                   power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False,\n",
    "                   warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "                   validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, \n",
    "                   )\n",
    "\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred=mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Métriques de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Matrice de confusion = \n",
      " [[317  16   1]\n",
      " [ 11  47   1]\n",
      " [  1   2  30]]\n",
      " Taux d'erreur = 0.07511737089201875\n",
      " Exactitude (Accuracy)= 0.9248826291079812\n"
     ]
    }
   ],
   "source": [
    "print(\" Matrice de confusion = \") \n",
    "print(\" \"+str(confusion_matrix(y_pred,y_test)))\n",
    "print(\" Taux d'erreur = \" +str(zero_one_loss(y_test, y_pred)))\n",
    "print(\" Exactitude (Accuracy)= \" +str(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3 : GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Utilisation de la méthode GridSearchCV qui trouve facilement les valeurs optimales parmi les valeurs données pour les paramètres pertinents (activation, solver, learning_rate, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_gs = MLPClassifier(max_iter=3000)\n",
    "parameter_space = {\n",
    "    'activation': ['relu', 'identity', 'logistic', 'tanh'],\n",
    "    'solver': ['adam', 'lbfgs', 'sgd'],\n",
    "    'learning_rate': ['constant','adaptive', 'invscaling'],\n",
    "    'max_iter': [200, 2000, 3000],\n",
    "}\n",
    "\n",
    "#n_jobs=-1 , -1 sert à utiliser tous les cœurs de processeur disponibles.\n",
    "#cv = 10 est pour la validation croisée, ici cela signifie 10 fois la validation croisée stratifiée (K-fold)\n",
    "clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=10)\n",
    "\n",
    "#Apprentissage / Entrainement de modèle\n",
    "clf.fit(X, y)\n",
    "\n",
    "#Affichage des scores pour toutes les combinaisons (modèles) possibles \n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "i=0\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    i=i+1    \n",
    "print(\"Le nombre de combinaisons (modèles) possible est : %r \" % (i)) \n",
    "print(\" \\n \")\n",
    "print(\"|  Mean  |   Std   |  Combinaison / Modèle \")\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f    | %0.03f   | %r\" % (mean, std, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Affichage du meilleur modèle (hyperparamètres optimaux parmi les valeurs données). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Meilleurs paramètres trouvés : \\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Test du meilleur modèle sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_pred = y_test , clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Métriques de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Matrice de confusion = \") \n",
    "print(\" \"+str(confusion_matrix(y_pred,y_test)))\n",
    "print(\" Taux d'erreur = \" +str(zero_one_loss(y_test, y_pred)))\n",
    "print(\" Exactitude (Accuracy)= \" +str(accuracy_score(y_test,y_pred)))\n",
    "print(\" précision = \" +str(precision_score(y_test, y_pred)))\n",
    "print(\" Rappel = \" +str(recall_score(y_test, y_pred)))\n",
    "print(\" La F meusure = \" +str( f1_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
